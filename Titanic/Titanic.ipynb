{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"encoded_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_csv, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "#### Categorical features\n",
    "\n",
    "- Survived - Survival - 0 = No, 1 = Yes - **Used for evaluating whether a person survived**\n",
    "- Sex - Sex \t\n",
    "- Embarked - Port of Embarkation - C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "#### Ordinal\n",
    "\n",
    "- Pclass - Ticket class - 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "#### Numerical features\n",
    "\n",
    "##### Discrete\n",
    "\n",
    "- SibSp - # of siblings / spouses aboard the Titanic \t\n",
    "- Parch - # of parents / children aboard the Titanic \n",
    "\n",
    "##### Continuous\n",
    "\n",
    "- Age - Age in years \t\t\n",
    "- Fare - Passenger fare \n",
    "\n",
    "#### Mixed/Error-prone/Unused\n",
    "\n",
    "- PassengerId - Id of person\n",
    "- Name - Name of Passenger\n",
    "- Ticket - Ticket number \n",
    "- Cabin - Cabin number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set warnings to not be displayed\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Divider:\n",
    "    '''\n",
    "    Table divider class\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_table, important_column):\n",
    "        '''\n",
    "        Constructor for divider\n",
    "\n",
    "        input_table - table to apply division on\n",
    "        important_column - y_column used for predictions\n",
    "        '''\n",
    "        self.result = []\n",
    "        self.input_table = input_table\n",
    "        self.important_column = important_column\n",
    "        self.connections = []\n",
    "        self.index = 0\n",
    "    \n",
    "    def get_result(self):\n",
    "        '''\n",
    "        Returns the result of calculations\n",
    "        '''\n",
    "        return self.result\n",
    "\n",
    "    def random_same_pk_fk(self, input_table, level):\n",
    "        '''\n",
    "        Recursively cluster randomly the columns\n",
    "        level - level of recursion\n",
    "        '''\n",
    "\n",
    "        input_table = input_table.copy()\n",
    "        \n",
    "        # Return if no columns\n",
    "        if len(input_table.columns) == 1:\n",
    "            return\n",
    "        \n",
    "        # Set up base table variables\n",
    "        base_index = self.index\n",
    "        self.index += 1\n",
    "        base_index_cols = input_table.index.names\n",
    "        \n",
    "        # Apply clustering for every cluster of columns\n",
    "        while len(input_table.columns) > 0:\n",
    "\n",
    "            # Randomly shuffle\n",
    "            self.index += 1\n",
    "            mylist = np.array(range(0, len(input_table)))\n",
    "            random.shuffle(mylist)\n",
    "\n",
    "            # Randomly pick n_splits columns\n",
    "            picked_columns = []\n",
    "            if len(input_table.columns) > 1:\n",
    "                picked_columns = input_table.sample(n=np.random.randint(1, len(input_table.columns)), axis='columns').columns\n",
    "            else:\n",
    "                picked_columns = input_table.columns       \n",
    "            \n",
    "            # Set new column names\n",
    "            PK_name = 'PK' + str(level + 1) + str(self.index)\n",
    "            FK_name = 'FK' + str(level + 1) + str(self.index)\n",
    "            \n",
    "            # Add new PK\n",
    "            recursed_table = input_table[picked_columns]\n",
    "            recursed_table.loc[:, PK_name] = mylist\n",
    "            recursed_table.set_index(PK_name, inplace = True)\n",
    "            \n",
    "            # Add new FK and remove columns associated with it\n",
    "            input_table.loc[:, FK_name] = mylist\n",
    "            input_table = input_table.groupby(input_table.index.names + [FK_name]).mean()\n",
    "            input_table = input_table.drop(picked_columns, axis = 1)\n",
    "            \n",
    "            # Add the connection to a list\n",
    "            self.connections.append(('table' + str(level) + str(base_index), FK_name,  \n",
    "                                     'table' + str(level + 1) + str(self.index), PK_name))\n",
    "            \n",
    "            # Append new FK table to result list\n",
    "            if len(recursed_table.columns) == 1:\n",
    "                self.result.append((level + 1, self.index, recursed_table))\n",
    "            \n",
    "            # Apply clustering recursively on smaller table\n",
    "            self.random_same_pk_fk(recursed_table, level + 1)\n",
    "        \n",
    "        # Reset the index and set FK columns as normal columns\n",
    "        input_table = input_table.reset_index()\n",
    "        input_table.set_index(base_index_cols, inplace = True)\n",
    "        self.result.append((level, base_index, input_table))\n",
    "    \n",
    "    def correlation(self, input_table, important_column, level):\n",
    "        '''\n",
    "        Recursively cluster most correlated columns to an \"important_column\"\n",
    "        important_column - colum of interest, most likely to be Y\n",
    "        input_table - table to apply the clustering on\n",
    "        '''\n",
    "\n",
    "        input_table = input_table.copy()\n",
    "\n",
    "        n_splits = 3\n",
    "        \n",
    "        # Return if no columns\n",
    "        if len(input_table.columns) == 0:\n",
    "            return\n",
    "        \n",
    "        # Set up base table variables\n",
    "        base_index = self.index\n",
    "        self.index += 1\n",
    "        base_index_cols = input_table.index.names\n",
    "\n",
    "        # Calculate correlation between columns and most important column\n",
    "        corr = abs(input_table.corr(method='spearman'))\n",
    "        corr = corr.drop([important_column], axis = 1)\n",
    "        \n",
    "        # Calculate quantiles based on correlation and n_splits\n",
    "        quantiles = []\n",
    "        for i in range(n_splits):\n",
    "            quantile = 1 - (i+1) / n_splits\n",
    "            quantiles.append(corr.loc[[important_column]].T.quantile(quantile)[0])\n",
    "        \n",
    "        # Apply clustering for every cluster of columns\n",
    "        for threshold in quantiles:\n",
    "            # Randomly shuffle\n",
    "            self.index += 1\n",
    "            mylist = np.array(range(0, len(input_table)))\n",
    "            random.shuffle(mylist)\n",
    "\n",
    "            # Break if no columns\n",
    "            if len(corr.columns) == 0 or len(input_table.columns) == 0:\n",
    "                break\n",
    "        \n",
    "            # Pick the new important column\n",
    "            new_important = corr.loc[[important_column]].idxmax(axis=1)[0]\n",
    "            # Pick all columns with correlation above quantile threshold\n",
    "            corr_columns = [col for col in corr.loc[[important_column]].columns if corr.loc[[important_column]][col][0] >= threshold]\n",
    "           \n",
    "            if len(corr_columns) == 0:\n",
    "                continue\n",
    "\n",
    "             # Set new column names\n",
    "            PK_name = 'PK' + str(level + 1) + str(self.index)\n",
    "            FK_name = 'FK' + str(level + 1) + str(self.index)\n",
    "            \n",
    "            # Add new PK\n",
    "            recursed_table = input_table[corr_columns]\n",
    "            recursed_table.loc[:, PK_name] = mylist\n",
    "            recursed_table.set_index(PK_name, inplace = True)\n",
    "            \n",
    "            # Add new FK and remove columns associated with it\n",
    "            input_table.loc[:, FK_name] = mylist\n",
    "            input_table = input_table.groupby(input_table.index.names + [FK_name]).mean()\n",
    "            input_table = input_table.drop(corr_columns, axis = 1)\n",
    "            corr = corr.drop(corr_columns, axis = 1)\n",
    "            \n",
    "            # Add the connection to a list\n",
    "            self.connections.append(('table' + str(level) + str(base_index), FK_name,  \n",
    "                                     'table' + str(level + 1) + str(self.index), PK_name))\n",
    "            \n",
    "            # Apply clustering recursively\n",
    "            self.correlation(recursed_table, new_important, level + 1)\n",
    "\n",
    "        # Reset the index and set FK columns as normal columns\n",
    "        input_table = input_table.reset_index()\n",
    "        input_table.set_index(base_index_cols, inplace = True)\n",
    "        self.result.append((level, base_index, input_table))\n",
    "\n",
    "    \n",
    "    def divide(self, strategy, path):\n",
    "        '''\n",
    "        Function used to divide the table\n",
    "        strategy - strategy of division\n",
    "        path - path to save output\n",
    "        '''\n",
    "\n",
    "        # Create output folder\n",
    "        os.makedirs(path, exist_ok=True) \n",
    "        \n",
    "        # Initialise fresh result and connections lists\n",
    "        self.__init__(self.input_table, self.important_column)\n",
    "        \n",
    "        # Pick strategy\n",
    "        if strategy == 'random_same_pk_fk':\n",
    "            input_table = self.input_table.groupby(self.input_table.index.names + [self.important_column]).mean()\n",
    "            self.random_same_pk_fk(input_table, 0)\n",
    "        elif strategy == 'correlation':\n",
    "            self.correlation(self.input_table, self.important_column, 0)\n",
    "        \n",
    "        # Sort result by recursion level and index\n",
    "        self.result.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "        # Print results and save every table to a file\n",
    "        print('Level, Index, Primary Key, Columns')\n",
    "        for (el, col, table) in self.result:\n",
    "            print(el, \" \", col, \" \", table.index.names, \" \", table.columns, \"\\n\")\n",
    "            table.to_csv(path + '/table' + str(el) + str(col) + '.csv')\n",
    "\n",
    "        # Initialise set of tuples in the form (table name, PK column)\n",
    "        all_tables = []\n",
    "\n",
    "        # Iterate over tables and fill data\n",
    "        for (el, col, table) in self.result:\n",
    "            # Add tables to set\n",
    "            all_tables.append((str('table' + str(el) + str(col)), table.index.names))\n",
    "\n",
    "        # Save connections to file\n",
    "        np.savetxt(path + \"/connections.csv\", self.connections, delimiter=',', fmt='%s')\n",
    "        \n",
    "        # Save tables names with their PK to file\n",
    "        all_tables = json.dumps(all_tables)\n",
    "        with open(path + '/tables.json', 'w') as outfile:\n",
    "            json.dump(all_tables, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise divider\n",
    "dv = Divider(train_data, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level, Index, Primary Key, Columns\n",
      "0   0   ['PassengerId']   Index(['FK12', 'FK111', 'FK117', 'Survived'], dtype='object') \n",
      "\n",
      "1   2   ['PK12']   Index(['FK24', 'FK28', 'Sex'], dtype='object') \n",
      "\n",
      "1   11   ['PK111']   Index(['FK213', 'Embarked'], dtype='object') \n",
      "\n",
      "1   17   ['PK117']   Index(['FK219', 'FK223', 'SibSp'], dtype='object') \n",
      "\n",
      "2   4   ['PK24']   Index(['Fare'], dtype='object') \n",
      "\n",
      "2   8   ['PK28']   Index(['Pclass'], dtype='object') \n",
      "\n",
      "2   13   ['PK213']   Index(['Parch'], dtype='object') \n",
      "\n",
      "2   19   ['PK219']   Index(['Age'], dtype='object') \n",
      "\n",
      "2   23   ['PK223']   Index(['Title'], dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply division\n",
    "dv.divide(strategy = \"correlation\", path = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['table00', ['PassengerId']], ['table12', ['PK12']], ['table111', ['PK111']], ['table117', ['PK117']], ['table24', ['PK24']], ['table28', ['PK28']], ['table213', ['PK213']], ['table219', ['PK219']], ['table223', ['PK223']]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "# Read data from tables - returns array of [table name, Primary key]\n",
    "read_tables = []\n",
    "with open('output/tables.json') as json_file:\n",
    "    read_tables = json.loads(json.load(json_file))\n",
    "print(read_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table00':              FK12  FK111  FK117  Survived\n",
      "PassengerId                              \n",
      "1             378    118    537         0\n",
      "2             309    647    871         1\n",
      "3             143    100    396         1\n",
      "4             356    501     67         1\n",
      "5             234    654    679         0\n",
      "...           ...    ...    ...       ...\n",
      "887           447    309    847         0\n",
      "888           428    524     17         1\n",
      "889           492    761     89         0\n",
      "890           763    669    296         1\n",
      "891           381     42    125         0\n",
      "\n",
      "[891 rows x 4 columns], 'table12':       FK24  FK28  Sex\n",
      "PK12                 \n",
      "0       54   486  0.0\n",
      "1      122   812  0.0\n",
      "2      606   370  1.0\n",
      "3      468   172  0.0\n",
      "4      839    42  0.0\n",
      "...    ...   ...  ...\n",
      "886    734   792  0.0\n",
      "887     52   509  0.0\n",
      "888    326   291  1.0\n",
      "889    586   855  1.0\n",
      "890    778   559  1.0\n",
      "\n",
      "[891 rows x 3 columns], 'table111':        FK213  Embarked\n",
      "PK111                 \n",
      "0        274       0.0\n",
      "1        848       2.0\n",
      "2        870       2.0\n",
      "3        671       2.0\n",
      "4        813       2.0\n",
      "...      ...       ...\n",
      "886      638       0.0\n",
      "887      445       2.0\n",
      "888      600       0.0\n",
      "889      845       2.0\n",
      "890      577       2.0\n",
      "\n",
      "[891 rows x 2 columns], 'table117':        FK219  FK223  SibSp\n",
      "PK117                     \n",
      "0        792    776      0\n",
      "1          9     13      0\n",
      "2        594    118      1\n",
      "3        527    800      0\n",
      "4        771    841      5\n",
      "...      ...    ...    ...\n",
      "886      645    482      0\n",
      "887      798    607      0\n",
      "888      461    834      0\n",
      "889      753    342      0\n",
      "890      353    531      0\n",
      "\n",
      "[891 rows x 3 columns], 'table24':          Fare\n",
      "PK24         \n",
      "743    7.2500\n",
      "513   71.2833\n",
      "112    7.9250\n",
      "319   53.1000\n",
      "312    8.0500\n",
      "...       ...\n",
      "752   13.0000\n",
      "604   30.0000\n",
      "377   23.4500\n",
      "187   30.0000\n",
      "569    7.7500\n",
      "\n",
      "[891 rows x 1 columns], 'table28':       Pclass\n",
      "PK28        \n",
      "486      0.0\n",
      "812      1.0\n",
      "370      0.0\n",
      "172      2.0\n",
      "42       2.0\n",
      "...      ...\n",
      "792      0.0\n",
      "509      2.0\n",
      "291      0.0\n",
      "855      2.0\n",
      "559      2.0\n",
      "\n",
      "[891 rows x 1 columns], 'table213':        Parch\n",
      "PK213       \n",
      "123        0\n",
      "719        0\n",
      "325        0\n",
      "126        0\n",
      "252        0\n",
      "...      ...\n",
      "141        0\n",
      "196        0\n",
      "524        2\n",
      "6          0\n",
      "65         0\n",
      "\n",
      "[891 rows x 1 columns], 'table219':         Age\n",
      "PK219      \n",
      "76     22.0\n",
      "280    38.0\n",
      "554    26.0\n",
      "573    35.0\n",
      "589    35.0\n",
      "...     ...\n",
      "719    27.0\n",
      "565    19.0\n",
      "799    23.0\n",
      "840    26.0\n",
      "247    32.0\n",
      "\n",
      "[891 rows x 1 columns], 'table223':        Title\n",
      "PK223       \n",
      "776      2.0\n",
      "13       2.0\n",
      "118      2.0\n",
      "800      2.0\n",
      "841      0.0\n",
      "...      ...\n",
      "482      2.0\n",
      "607      3.0\n",
      "834      1.0\n",
      "342      1.0\n",
      "531      2.0\n",
      "\n",
      "[891 rows x 1 columns]}\n"
     ]
    }
   ],
   "source": [
    "# Read data from tables - read tables as pandas and set index as Primary key column\n",
    "read_tables_content = dict()\n",
    "for [table, pk] in read_tables:\n",
    "    read_tables_content[table] = pd.read_csv('output/' + table + '.csv', index_col=pk)\n",
    "    \n",
    "print(read_tables_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FK12</th>\n",
       "      <th>FK111</th>\n",
       "      <th>FK117</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>378</td>\n",
       "      <td>118</td>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309</td>\n",
       "      <td>647</td>\n",
       "      <td>871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>100</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>501</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>234</td>\n",
       "      <td>654</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>447</td>\n",
       "      <td>309</td>\n",
       "      <td>847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>428</td>\n",
       "      <td>524</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>492</td>\n",
       "      <td>761</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>763</td>\n",
       "      <td>669</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>381</td>\n",
       "      <td>42</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FK12  FK111  FK117  Survived\n",
       "PassengerId                              \n",
       "1             378    118    537         0\n",
       "2             309    647    871         1\n",
       "3             143    100    396         1\n",
       "4             356    501     67         1\n",
       "5             234    654    679         0\n",
       "...           ...    ...    ...       ...\n",
       "887           447    309    847         0\n",
       "888           428    524     17         1\n",
       "889           492    761     89         0\n",
       "890           763    669    296         1\n",
       "891           381     42    125         0\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test table reading\n",
    "table01 = pd.read_csv('output/table00.csv', index_col='PassengerId')\n",
    "table01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('table00', 'FK12'), ('table12', 'PK12')), (('table12', 'FK24'), ('table24', 'PK24')), (('table12', 'FK28'), ('table28', 'PK28')), (('table00', 'FK111'), ('table111', 'PK111')), (('table111', 'FK213'), ('table213', 'PK213')), (('table00', 'FK117'), ('table117', 'PK117')), (('table117', 'FK219'), ('table219', 'PK219')), (('table117', 'FK223'), ('table223', 'PK223'))]\n"
     ]
    }
   ],
   "source": [
    "# Read all ((table1, PK), (table2, FK)) relations and add them to a list\n",
    "read_connections = map(lambda x: ((x[0], x[1]), (x[2], x[3])), genfromtxt('output/connections.csv', delimiter=',', dtype='str'))\n",
    "read_connections = list(read_connections)\n",
    "print(read_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FK12  FK111  FK117  Survived  FK24  FK28  Sex\n",
      "0     378    118    537         0   743   175  1.0\n",
      "1     309    647    871         1   513   744  0.0\n",
      "2     143    100    396         1   112   800  0.0\n",
      "3     356    501     67         1   319   633  0.0\n",
      "4     234    654    679         0   312   271  1.0\n",
      "..    ...    ...    ...       ...   ...   ...  ...\n",
      "886   447    309    847         0   752    33  1.0\n",
      "887   428    524     17         1   604   884  0.0\n",
      "888   492    761     89         0   377   807  0.0\n",
      "889   763    669    296         1   187   516  1.0\n",
      "890   381     42    125         0   569   297  1.0\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "     FK24  FK28  Sex      Fare\n",
      "0      54   486  0.0   78.2667\n",
      "1     122   812  0.0   13.0000\n",
      "2     606   370  1.0   55.9000\n",
      "3     468   172  0.0   25.4667\n",
      "4     839    42  0.0    7.2250\n",
      "..    ...   ...  ...       ...\n",
      "886   734   792  0.0  120.0000\n",
      "887    52   509  0.0   11.1333\n",
      "888   326   291  1.0  135.6333\n",
      "889   586   855  1.0    6.4375\n",
      "890   778   559  1.0    7.8958\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "     FK24  FK28  Sex  Pclass\n",
      "0      54   486  0.0     0.0\n",
      "1     122   812  0.0     1.0\n",
      "2     606   370  1.0     0.0\n",
      "3     468   172  0.0     2.0\n",
      "4     839    42  0.0     2.0\n",
      "..    ...   ...  ...     ...\n",
      "886   734   792  0.0     0.0\n",
      "887    52   509  0.0     2.0\n",
      "888   326   291  1.0     0.0\n",
      "889   586   855  1.0     2.0\n",
      "890   778   559  1.0     2.0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "     FK12  FK111  FK117  Survived  FK213  Embarked\n",
      "0     378    118    537         0    123       2.0\n",
      "1     309    647    871         1    719       0.0\n",
      "2     143    100    396         1    325       2.0\n",
      "3     356    501     67         1    126       2.0\n",
      "4     234    654    679         0    252       2.0\n",
      "..    ...    ...    ...       ...    ...       ...\n",
      "886   447    309    847         0    141       2.0\n",
      "887   428    524     17         1    196       2.0\n",
      "888   492    761     89         0    524       2.0\n",
      "889   763    669    296         1      6       0.0\n",
      "890   381     42    125         0     65       1.0\n",
      "\n",
      "[891 rows x 6 columns]\n",
      "     FK213  Embarked  Parch\n",
      "0      274       0.0      0\n",
      "1      848       2.0      1\n",
      "2      870       2.0      0\n",
      "3      671       2.0      1\n",
      "4      813       2.0      0\n",
      "..     ...       ...    ...\n",
      "886    638       0.0      0\n",
      "887    445       2.0      0\n",
      "888    600       0.0      0\n",
      "889    845       2.0      0\n",
      "890    577       2.0      2\n",
      "\n",
      "[891 rows x 3 columns]\n",
      "     FK12  FK111  FK117  Survived  FK219  FK223  SibSp\n",
      "0     378    118    537         0     76    717      1\n",
      "1     309    647    871         1    280     66      1\n",
      "2     143    100    396         1    554    187      0\n",
      "3     356    501     67         1    573    833      1\n",
      "4     234    654    679         0    589    481      0\n",
      "..    ...    ...    ...       ...    ...    ...    ...\n",
      "886   447    309    847         0    719    594      0\n",
      "887   428    524     17         1    565    256      0\n",
      "888   492    761     89         0    799    388      1\n",
      "889   763    669    296         1    840    497      0\n",
      "890   381     42    125         0    247    128      0\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "     FK219  FK223  SibSp   Age\n",
      "0      792    776      0  32.0\n",
      "1        9     13      0  19.0\n",
      "2      594    118      1  25.0\n",
      "3      527    800      0  18.0\n",
      "4      771    841      5  11.0\n",
      "..     ...    ...    ...   ...\n",
      "886    645    482      0  21.0\n",
      "887    798    607      0  41.0\n",
      "888    461    834      0  27.0\n",
      "889    753    342      0  24.0\n",
      "890    353    531      0  59.0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "     FK219  FK223  SibSp  Title\n",
      "0      792    776      0    2.0\n",
      "1        9     13      0    2.0\n",
      "2      594    118      1    2.0\n",
      "3      527    800      0    2.0\n",
      "4      771    841      5    0.0\n",
      "..     ...    ...    ...    ...\n",
      "886    645    482      0    2.0\n",
      "887    798    607      0    3.0\n",
      "888    461    834      0    1.0\n",
      "889    753    342      0    1.0\n",
      "890    353    531      0    2.0\n",
      "\n",
      "[891 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example of joining tables by going over the relations list\n",
    "for ((table1, index1), (table2, index2)) in read_connections:\n",
    "    print(read_tables_content[table1].merge(read_tables_content[table2], left_on=index1, right_on=index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
