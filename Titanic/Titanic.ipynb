{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"encoded_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_csv, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "#### Categorical features\n",
    "\n",
    "- Survived - Survival - 0 = No, 1 = Yes - **Used for evaluating whether a person survived**\n",
    "- Sex - Sex \t\n",
    "- Embarked - Port of Embarkation - C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "#### Ordinal\n",
    "\n",
    "- Pclass - Ticket class - 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "#### Numerical features\n",
    "\n",
    "##### Discrete\n",
    "\n",
    "- SibSp - # of siblings / spouses aboard the Titanic \t\n",
    "- Parch - # of parents / children aboard the Titanic \n",
    "\n",
    "##### Continuous\n",
    "\n",
    "- Age - Age in years \t\t\n",
    "- Fare - Passenger fare \n",
    "\n",
    "#### Mixed/Error-prone/Unused\n",
    "\n",
    "- PassengerId - Id of person\n",
    "- Name - Name of Passenger\n",
    "- Ticket - Ticket number \n",
    "- Cabin - Cabin number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Set warnings to not be displayed\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Divider:\n",
    "    '''\n",
    "    Table divider class\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_table, important_column):\n",
    "        '''\n",
    "        Constructor for divider\n",
    "\n",
    "        input_table - table to apply division on\n",
    "        important_column - y_column used for predictions\n",
    "        '''\n",
    "        self.result = []\n",
    "        self.input_table = input_table.copy()\n",
    "        self.important_column = important_column\n",
    "        self.connections = []\n",
    "        self.index = 0\n",
    "    \n",
    "    def get_result(self):\n",
    "        '''\n",
    "        Returns the result of calculations\n",
    "        '''\n",
    "        return self.result\n",
    "\n",
    "    def random_same_pk_fk(self, input_table, level, onehot=False, overlap=False):\n",
    "        '''\n",
    "        Recursively cluster randomly the columns\n",
    "        level - level of recursion\n",
    "        '''\n",
    "\n",
    "        input_table = input_table.copy()\n",
    "        \n",
    "        # Return if no columns\n",
    "        if len(input_table.columns) <= 1:\n",
    "            return\n",
    "        \n",
    "        # Set up base table variables\n",
    "        base_index = self.index\n",
    "        self.index += 1\n",
    "        base_index_cols = input_table.index.names\n",
    "        \n",
    "        # Apply clustering for every cluster of columns\n",
    "        while len(input_table.columns) > 0:\n",
    "\n",
    "            # Randomly shuffle\n",
    "            self.index += 1\n",
    "            mylist = np.array(range(0, len(input_table)))\n",
    "            random.shuffle(mylist)\n",
    "\n",
    "            # Randomly pick n_splits columns\n",
    "            picked_columns = []\n",
    "            if len(input_table.columns) > 1:\n",
    "                picked_columns = input_table.sample(n=np.random.randint(1, len(input_table.columns)), axis='columns').columns\n",
    "            else:\n",
    "                picked_columns = input_table.columns       \n",
    "            \n",
    "            # Set new column names\n",
    "            PK_name = 'PK' + str(level + 1) + str(self.index)\n",
    "            FK_name = 'FK' + str(level + 1) + str(self.index)\n",
    "            \n",
    "            # Add new PK\n",
    "            recursed_table = input_table[picked_columns]\n",
    "            recursed_table.loc[:, PK_name] = mylist\n",
    "            recursed_table.set_index(PK_name, inplace = True)\n",
    "            \n",
    "            # Add new FK and remove columns associated with it\n",
    "            input_table.loc[:, FK_name] = mylist\n",
    "            input_table = input_table.groupby(input_table.index.names + [FK_name]).mean()\n",
    "            input_table = input_table.drop(picked_columns, axis = 1)\n",
    "            \n",
    "            # Add the connection to a list\n",
    "            self.connections.append(('table' + str(level) + str(base_index), FK_name,  \n",
    "                                     'table' + str(level + 1) + str(self.index), PK_name))\n",
    "            \n",
    "            # Append new FK table to result list\n",
    "            if len(recursed_table.columns) == 1:\n",
    "                # Check if you need to apply oneHotEncoding\n",
    "                if onehot is True and len(recursed_table[recursed_table.columns[0]].unique()) < 7:\n",
    "                    oneHotEncoder = OneHotEncoder()\n",
    "                    encoded_col = pd.DataFrame(oneHotEncoder.fit_transform(recursed_table[[recursed_table.columns[0]]]).toarray())\n",
    "\n",
    "                    # Concatenate the 2 tables\n",
    "                    recursed_table = pd.concat([recursed_table.reset_index(), encoded_col], axis=1, copy=False, join='inner')\n",
    "\n",
    "                    # Readd the index column\n",
    "                    recursed_table.loc[:, PK_name] = mylist\n",
    "                    recursed_table.set_index(PK_name, inplace = True)\n",
    "                \n",
    "                # Append single-column table to result\n",
    "                self.result.append((level + 1, self.index, recursed_table))\n",
    "                continue\n",
    "            else:\n",
    "                #Perform overlaping with probability\n",
    "                p = 0.3\n",
    "                if np.random.rand() <= p:\n",
    "                    picked_column = recursed_table.sample(n=1, axis='columns').columns\n",
    "                    input_table[picked_column] = recursed_table[picked_column].copy()\n",
    "            \n",
    "            # Apply clustering recursively on smaller table\n",
    "            self.random_same_pk_fk(recursed_table, level + 1, onehot=onehot, overlap=overlap)\n",
    "        \n",
    "        # Reset the index and set FK columns as normal columns\n",
    "        input_table = input_table.reset_index()\n",
    "        input_table.set_index(base_index_cols, inplace = True)\n",
    "        self.result.append((level, base_index, input_table))\n",
    "    \n",
    "    def correlation(self, input_table, important_column, level):\n",
    "        '''\n",
    "        Recursively cluster most correlated columns to an \"important_column\"\n",
    "        important_column - colum of interest, most likely to be Y\n",
    "        input_table - table to apply the clustering on\n",
    "        '''\n",
    "\n",
    "        input_table = input_table.copy()\n",
    "\n",
    "        n_splits = 3\n",
    "        \n",
    "        # Return if no columns\n",
    "        if len(input_table.columns) == 0:\n",
    "            return\n",
    "        \n",
    "        # Set up base table variables\n",
    "        base_index = self.index\n",
    "        self.index += 1\n",
    "        base_index_cols = input_table.index.names\n",
    "\n",
    "        # Calculate correlation between columns and most important column\n",
    "        corr = abs(input_table.corr(method='spearman'))\n",
    "        corr = corr.drop([important_column], axis = 1)\n",
    "        \n",
    "        # Calculate quantiles based on correlation and n_splits\n",
    "        quantiles = []\n",
    "        for i in range(n_splits):\n",
    "            quantile = 1 - (i+1) / n_splits\n",
    "            quantiles.append(corr.loc[[important_column]].T.quantile(quantile)[0])\n",
    "        \n",
    "        # Apply clustering for every cluster of columns\n",
    "        for threshold in quantiles:\n",
    "            # Randomly shuffle\n",
    "            self.index += 1\n",
    "            mylist = np.array(range(0, len(input_table)))\n",
    "            random.shuffle(mylist)\n",
    "\n",
    "            # Break if no columns\n",
    "            if len(corr.columns) == 0 or len(input_table.columns) == 0:\n",
    "                break\n",
    "        \n",
    "            # Pick the new important column\n",
    "            new_important = corr.loc[[important_column]].idxmax(axis=1)[0]\n",
    "            # Pick all columns with correlation above quantile threshold\n",
    "            corr_columns = [col for col in corr.loc[[important_column]].columns if corr.loc[[important_column]][col][0] >= threshold]\n",
    "           \n",
    "            if len(corr_columns) == 0:\n",
    "                continue\n",
    "\n",
    "             # Set new column names\n",
    "            PK_name = 'PK' + str(level + 1) + str(self.index)\n",
    "            FK_name = 'FK' + str(level + 1) + str(self.index)\n",
    "            \n",
    "            # Add new PK\n",
    "            recursed_table = input_table[corr_columns]\n",
    "            recursed_table.loc[:, PK_name] = mylist\n",
    "            recursed_table.set_index(PK_name, inplace = True)\n",
    "            \n",
    "            # Add new FK and remove columns associated with it\n",
    "            input_table.loc[:, FK_name] = mylist\n",
    "            input_table = input_table.groupby(input_table.index.names + [FK_name]).mean()\n",
    "            input_table = input_table.drop(corr_columns, axis = 1)\n",
    "            corr = corr.drop(corr_columns, axis = 1)\n",
    "            \n",
    "            # Add the connection to a list\n",
    "            self.connections.append(('table' + str(level) + str(base_index), FK_name,  \n",
    "                                     'table' + str(level + 1) + str(self.index), PK_name))\n",
    "            \n",
    "            # Apply clustering recursively\n",
    "            self.correlation(recursed_table, new_important, level + 1)\n",
    "\n",
    "        # Reset the index and set FK columns as normal columns\n",
    "        input_table = input_table.reset_index()\n",
    "        input_table.set_index(base_index_cols, inplace = True)\n",
    "        self.result.append((level, base_index, input_table))\n",
    "\n",
    "    \n",
    "    def divide(self, strategy, path, onehot=False, overlap=False):\n",
    "        '''\n",
    "        Function used to divide the table\n",
    "        strategy - strategy of division\n",
    "        path - path to save output\n",
    "        '''\n",
    "\n",
    "        # Create output folder\n",
    "        os.makedirs(path, exist_ok=True) \n",
    "        \n",
    "        # Initialise fresh result and connections lists\n",
    "        self.__init__(self.input_table, self.important_column)\n",
    "        \n",
    "        # Pick strategy\n",
    "        if strategy == 'random':\n",
    "            input_table = self.input_table.groupby(self.input_table.index.names + [self.important_column]).mean()\n",
    "            self.random_same_pk_fk(input_table, 0, onehot=onehot, overlap=overlap)\n",
    "        elif strategy == 'correlation':\n",
    "            self.correlation(self.input_table, self.important_column, 0)\n",
    "        \n",
    "        # Sort result by recursion level and index\n",
    "        self.result.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "        # Print results and save every table to a file\n",
    "        print('Level, Index, Primary Key, Columns')\n",
    "        for (el, col, table) in self.result:\n",
    "            print(el, \" \", col, \" \", table.index.names, \" \", table.columns, \"\\n\")\n",
    "            table.to_csv(path + '/table' + str(el) + str(col) + '.csv')\n",
    "\n",
    "        # Initialise set of tuples in the form (table name, PK column)\n",
    "        all_tables = []\n",
    "\n",
    "        # Iterate over tables and fill data\n",
    "        for (el, col, table) in self.result:\n",
    "            # Add tables to set\n",
    "            all_tables.append((str('table' + str(el) + str(col)), table.index.names))\n",
    "\n",
    "        # Save connections to file\n",
    "        np.savetxt(path + \"/connections.csv\", self.connections, delimiter=',', fmt='%s')\n",
    "        \n",
    "        # Save tables names with their PK to file\n",
    "        all_tables = json.dumps(all_tables)\n",
    "        with open(path + '/tables.json', 'w') as outfile:\n",
    "            json.dump(all_tables, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise divider\n",
    "dv = Divider(train_data, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level, Index, Primary Key, Columns\n",
      "0   0   ['PassengerId', 'Survived']   Index(['FK12', 'FK117'], dtype='object') \n",
      "\n",
      "1   2   ['PK12']   Index(['FK24', 'FK212', 'FK216'], dtype='object') \n",
      "\n",
      "1   17   ['PK117']   Index(['Title'], dtype='object') \n",
      "\n",
      "2   4   ['PK24']   Index(['FK36', 'FK37', 'FK311'], dtype='object') \n",
      "\n",
      "2   12   ['PK212']   Index(['FK314', 'FK315'], dtype='object') \n",
      "\n",
      "2   16   ['PK216']   Index(['SibSp'], dtype='object') \n",
      "\n",
      "3   6   ['PK36']   Index(['Embarked'], dtype='object') \n",
      "\n",
      "3   7   ['PK37']   Index(['FK49', 'FK410'], dtype='object') \n",
      "\n",
      "3   11   ['PK311']   Index(['Pclass'], dtype='object') \n",
      "\n",
      "3   14   ['PK314']   Index(['Fare'], dtype='object') \n",
      "\n",
      "3   15   ['PK315']   Index(['Parch'], dtype='object') \n",
      "\n",
      "4   9   ['PK49']   Index(['Age'], dtype='object') \n",
      "\n",
      "4   10   ['PK410']   Index(['Sex'], dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply division\n",
    "# dv.divide(strategy = \"correlation\", path = 'output')\n",
    "# dv.divide(strategy = \"random\", path = 'output')\n",
    "# dv.divide(strategy = \"random\", path = 'output', onehot=True)\n",
    "dv.divide(strategy='random', path='output', overlap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['table00', ['PassengerId', 'Survived']], ['table12', ['PK12']], ['table117', ['PK117']], ['table24', ['PK24']], ['table212', ['PK212']], ['table216', ['PK216']], ['table36', ['PK36']], ['table37', ['PK37']], ['table311', ['PK311']], ['table314', ['PK314']], ['table315', ['PK315']], ['table49', ['PK49']], ['table410', ['PK410']]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "# Read data from tables - returns array of [table name, Primary key]\n",
    "read_tables = []\n",
    "with open('output/tables.json') as json_file:\n",
    "    read_tables = json.loads(json.load(json_file))\n",
    "print(read_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table00':                       FK12  FK117\n",
      "PassengerId Survived             \n",
      "1           0          859     60\n",
      "2           1           38    645\n",
      "3           1          223    754\n",
      "4           1          127     16\n",
      "5           0          742    395\n",
      "...                    ...    ...\n",
      "887         0          258    472\n",
      "888         1          737    107\n",
      "889         0           34    425\n",
      "890         1          200    225\n",
      "891         0          234    538\n",
      "\n",
      "[891 rows x 2 columns], 'table12':       FK24  FK212  FK216\n",
      "PK12                    \n",
      "0      158    321    441\n",
      "1      471    698    830\n",
      "2      379    467    502\n",
      "3       78    672    276\n",
      "4      765    687    386\n",
      "...    ...    ...    ...\n",
      "886    594    695      0\n",
      "887    248    570    357\n",
      "888    792    652     70\n",
      "889    574    524    317\n",
      "890    490    833    575\n",
      "\n",
      "[891 rows x 3 columns], 'table117':        Title\n",
      "PK117       \n",
      "60       2.0\n",
      "645      3.0\n",
      "754      1.0\n",
      "16       3.0\n",
      "395      2.0\n",
      "...      ...\n",
      "472      4.0\n",
      "107      1.0\n",
      "425      1.0\n",
      "225      2.0\n",
      "538      2.0\n",
      "\n",
      "[891 rows x 1 columns], 'table24':       FK36  FK37  FK311\n",
      "PK24                   \n",
      "0      873   133    777\n",
      "1      174   327     83\n",
      "2      616     4    310\n",
      "3      304    49    737\n",
      "4      578   122    718\n",
      "...    ...   ...    ...\n",
      "886     53   106     92\n",
      "887    140   642    857\n",
      "888    595   760    794\n",
      "889    693   104    159\n",
      "890    464   129    667\n",
      "\n",
      "[891 rows x 3 columns], 'table212':        FK314  FK315\n",
      "PK212              \n",
      "0        606    210\n",
      "1        123    336\n",
      "2        144    111\n",
      "3        718     55\n",
      "4        752    449\n",
      "...      ...    ...\n",
      "886      367    523\n",
      "887      482    195\n",
      "888      815    550\n",
      "889      862    247\n",
      "890      713    132\n",
      "\n",
      "[891 rows x 2 columns], 'table216':        SibSp\n",
      "PK216       \n",
      "441        0\n",
      "830        1\n",
      "502        1\n",
      "276        1\n",
      "386        0\n",
      "...      ...\n",
      "0          0\n",
      "357        0\n",
      "70         0\n",
      "317        0\n",
      "575        0\n",
      "\n",
      "[891 rows x 1 columns], 'table36':       Embarked\n",
      "PK36          \n",
      "420        2.0\n",
      "525        0.0\n",
      "212        2.0\n",
      "228        2.0\n",
      "176        2.0\n",
      "...        ...\n",
      "877        2.0\n",
      "689        2.0\n",
      "308        2.0\n",
      "653        0.0\n",
      "30         1.0\n",
      "\n",
      "[891 rows x 1 columns], 'table37':       FK49  FK410\n",
      "PK37             \n",
      "0      282    820\n",
      "1      809    417\n",
      "2      786    669\n",
      "3      306    643\n",
      "4      766    814\n",
      "...    ...    ...\n",
      "886    454    179\n",
      "887    475    784\n",
      "888    545    595\n",
      "889    880    791\n",
      "890     63    671\n",
      "\n",
      "[891 rows x 2 columns], 'table311':        Pclass\n",
      "PK311        \n",
      "777       0.0\n",
      "83        0.0\n",
      "310       2.0\n",
      "737       2.0\n",
      "718       2.0\n",
      "...       ...\n",
      "92        0.0\n",
      "857       0.0\n",
      "794       0.0\n",
      "159       2.0\n",
      "667       0.0\n",
      "\n",
      "[891 rows x 1 columns], 'table314':            Fare\n",
      "PK314          \n",
      "189     69.3000\n",
      "663     14.5000\n",
      "94      24.1500\n",
      "405     55.9000\n",
      "511     26.5500\n",
      "...         ...\n",
      "799      8.0500\n",
      "618     13.0000\n",
      "808     13.0000\n",
      "763    153.4625\n",
      "796     26.2500\n",
      "\n",
      "[891 rows x 1 columns], 'table315':        Parch\n",
      "PK315       \n",
      "210        2\n",
      "336        0\n",
      "111        2\n",
      "55         0\n",
      "449        0\n",
      "...      ...\n",
      "523        0\n",
      "195        0\n",
      "550        0\n",
      "247        0\n",
      "132        0\n",
      "\n",
      "[891 rows x 1 columns], 'table49':        Age\n",
      "PK49      \n",
      "116   50.0\n",
      "762   49.0\n",
      "766   27.0\n",
      "834   19.0\n",
      "760   28.0\n",
      "...    ...\n",
      "68    48.0\n",
      "48    38.0\n",
      "580   49.0\n",
      "872   32.0\n",
      "240   35.0\n",
      "\n",
      "[891 rows x 1 columns], 'table410':        Sex\n",
      "PK410     \n",
      "820    1.0\n",
      "417    1.0\n",
      "669    1.0\n",
      "643    0.0\n",
      "814    1.0\n",
      "...    ...\n",
      "179    1.0\n",
      "784    1.0\n",
      "595    1.0\n",
      "791    1.0\n",
      "671    1.0\n",
      "\n",
      "[891 rows x 1 columns]}\n"
     ]
    }
   ],
   "source": [
    "# Read data from tables - read tables as pandas and set index as Primary key column\n",
    "read_tables_content = dict()\n",
    "for [table, pk] in read_tables:\n",
    "    read_tables_content[table] = pd.read_csv('output/' + table + '.csv', index_col=pk)\n",
    "    \n",
    "print(read_tables_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>FK12</th>\n",
       "      <th>FK117</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>859</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>742</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  FK12  FK117\n",
       "PassengerId                       \n",
       "1                   0   859     60\n",
       "2                   1    38    645\n",
       "3                   1   223    754\n",
       "4                   1   127     16\n",
       "5                   0   742    395\n",
       "...               ...   ...    ...\n",
       "887                 0   258    472\n",
       "888                 1   737    107\n",
       "889                 0    34    425\n",
       "890                 1   200    225\n",
       "891                 0   234    538\n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test table reading\n",
    "table01 = pd.read_csv('output/table00.csv', index_col='PassengerId')\n",
    "table01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('table00', 'FK12'), ('table12', 'PK12')), (('table12', 'FK24'), ('table24', 'PK24')), (('table24', 'FK36'), ('table36', 'PK36')), (('table24', 'FK37'), ('table37', 'PK37')), (('table37', 'FK49'), ('table49', 'PK49')), (('table37', 'FK410'), ('table410', 'PK410')), (('table24', 'FK311'), ('table311', 'PK311')), (('table12', 'FK212'), ('table212', 'PK212')), (('table212', 'FK314'), ('table314', 'PK314')), (('table212', 'FK315'), ('table315', 'PK315')), (('table12', 'FK216'), ('table216', 'PK216')), (('table00', 'FK117'), ('table117', 'PK117'))]\n"
     ]
    }
   ],
   "source": [
    "# Read all ((table1, PK), (table2, FK)) relations and add them to a list\n",
    "read_connections = map(lambda x: ((x[0], x[1]), (x[2], x[3])), genfromtxt('output/connections.csv', delimiter=',', dtype='str'))\n",
    "read_connections = list(read_connections)\n",
    "print(read_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FK12  FK117  FK24  FK212  FK216\n",
      "0     859     60   220    471    547\n",
      "1      38    645   375    390    297\n",
      "2     223    754   273    557     38\n",
      "3     127     16   645    324    674\n",
      "4     742    395   291    357    452\n",
      "..    ...    ...   ...    ...    ...\n",
      "886   258    472   587    692    290\n",
      "887   737    107   506    662    528\n",
      "888    34    425   345    281    716\n",
      "889   200    225   584    263    427\n",
      "890   234    538    29     93    647\n",
      "\n",
      "[891 rows x 5 columns]\n",
      "     FK24  FK212  FK216  FK36  FK37  FK311\n",
      "0     158    321    441   190   862    283\n",
      "1     471    698    830   400   586    574\n",
      "2     379    467    502   256   381    764\n",
      "3      78    672    276   660   652    127\n",
      "4     765    687    386   559   223     67\n",
      "..    ...    ...    ...   ...   ...    ...\n",
      "886   594    695      0   134   353    251\n",
      "887   248    570    357   858   120    709\n",
      "888   792    652     70   208   654    170\n",
      "889   574    524    317   703   858     50\n",
      "890   490    833    575   456   155    554\n",
      "\n",
      "[891 rows x 6 columns]\n",
      "     FK36  FK37  FK311  Embarked\n",
      "0     873   133    777       0.0\n",
      "1     174   327     83       0.0\n",
      "2     616     4    310       0.0\n",
      "3     304    49    737       2.0\n",
      "4     578   122    718       2.0\n",
      "..    ...   ...    ...       ...\n",
      "886    53   106     92       2.0\n",
      "887   140   642    857       2.0\n",
      "888   595   760    794       2.0\n",
      "889   693   104    159       2.0\n",
      "890   464   129    667       0.0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "     FK36  FK37  FK311  FK49  FK410\n",
      "0     873   133    777   116    481\n",
      "1     174   327     83   762     62\n",
      "2     616     4    310   766    814\n",
      "3     304    49    737   834     90\n",
      "4     578   122    718   760    866\n",
      "..    ...   ...    ...   ...    ...\n",
      "886    53   106     92    68    222\n",
      "887   140   642    857    48    830\n",
      "888   595   760    794   580    537\n",
      "889   693   104    159   872    718\n",
      "890   464   129    667   240    280\n",
      "\n",
      "[891 rows x 5 columns]\n",
      "     FK49  FK410   Age\n",
      "0     282    820   9.0\n",
      "1     809    417  30.0\n",
      "2     786    669  38.0\n",
      "3     306    643  18.0\n",
      "4     766    814  27.0\n",
      "..    ...    ...   ...\n",
      "886   454    179  45.5\n",
      "887   475    784  16.0\n",
      "888   545    595  28.0\n",
      "889   880    791  17.0\n",
      "890    63    671  16.0\n",
      "\n",
      "[891 rows x 3 columns]\n",
      "     FK49  FK410  Sex\n",
      "0     282    820  1.0\n",
      "1     809    417  1.0\n",
      "2     786    669  1.0\n",
      "3     306    643  0.0\n",
      "4     766    814  1.0\n",
      "..    ...    ...  ...\n",
      "886   454    179  1.0\n",
      "887   475    784  1.0\n",
      "888   545    595  1.0\n",
      "889   880    791  1.0\n",
      "890    63    671  1.0\n",
      "\n",
      "[891 rows x 3 columns]\n",
      "     FK36  FK37  FK311  Pclass\n",
      "0     873   133    777     0.0\n",
      "1     174   327     83     0.0\n",
      "2     616     4    310     2.0\n",
      "3     304    49    737     2.0\n",
      "4     578   122    718     2.0\n",
      "..    ...   ...    ...     ...\n",
      "886    53   106     92     0.0\n",
      "887   140   642    857     0.0\n",
      "888   595   760    794     0.0\n",
      "889   693   104    159     2.0\n",
      "890   464   129    667     0.0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "     FK24  FK212  FK216  FK314  FK315\n",
      "0     158    321    441    189    118\n",
      "1     471    698    830    663     64\n",
      "2     379    467    502     94    372\n",
      "3      78    672    276    405    306\n",
      "4     765    687    386    511    688\n",
      "..    ...    ...    ...    ...    ...\n",
      "886   594    695      0    799    754\n",
      "887   248    570    357    618    242\n",
      "888   792    652     70    808    494\n",
      "889   574    524    317    763    685\n",
      "890   490    833    575    796    838\n",
      "\n",
      "[891 rows x 5 columns]\n",
      "     FK314  FK315     Fare\n",
      "0      606    210  41.5792\n",
      "1      123    336   9.5000\n",
      "2      144    111  27.9000\n",
      "3      718     55  13.0000\n",
      "4      752    449  25.5875\n",
      "..     ...    ...      ...\n",
      "886    367    523  35.5000\n",
      "887    482    195   7.7292\n",
      "888    815    550  10.5000\n",
      "889    862    247   8.0500\n",
      "890    713    132   7.2500\n",
      "\n",
      "[891 rows x 3 columns]\n",
      "     FK314  FK315  Parch\n",
      "0      606    210      2\n",
      "1      123    336      0\n",
      "2      144    111      2\n",
      "3      718     55      0\n",
      "4      752    449      0\n",
      "..     ...    ...    ...\n",
      "886    367    523      0\n",
      "887    482    195      0\n",
      "888    815    550      0\n",
      "889    862    247      0\n",
      "890    713    132      0\n",
      "\n",
      "[891 rows x 3 columns]\n",
      "     FK24  FK212  FK216  SibSp\n",
      "0     158    321    441      0\n",
      "1     471    698    830      1\n",
      "2     379    467    502      1\n",
      "3      78    672    276      1\n",
      "4     765    687    386      0\n",
      "..    ...    ...    ...    ...\n",
      "886   594    695      0      0\n",
      "887   248    570    357      0\n",
      "888   792    652     70      0\n",
      "889   574    524    317      0\n",
      "890   490    833    575      0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "     FK12  FK117  Title\n",
      "0     859     60    2.0\n",
      "1      38    645    3.0\n",
      "2     223    754    1.0\n",
      "3     127     16    3.0\n",
      "4     742    395    2.0\n",
      "..    ...    ...    ...\n",
      "886   258    472    4.0\n",
      "887   737    107    1.0\n",
      "888    34    425    1.0\n",
      "889   200    225    2.0\n",
      "890   234    538    2.0\n",
      "\n",
      "[891 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example of joining tables by going over the relations list\n",
    "for ((table1, index1), (table2, index2)) in read_connections:\n",
    "    print(read_tables_content[table1].merge(read_tables_content[table2], left_on=index1, right_on=index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
