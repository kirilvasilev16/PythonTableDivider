{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"encoded_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_csv, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "#### Categorical features\n",
    "\n",
    "- Survived - Survival - 0 = No, 1 = Yes - **Used for evaluating whether a person survived**\n",
    "- Sex - Sex \t\n",
    "- Embarked - Port of Embarkation - C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "#### Ordinal\n",
    "\n",
    "- Pclass - Ticket class - 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "#### Numerical features\n",
    "\n",
    "##### Discrete\n",
    "\n",
    "- SibSp - # of siblings / spouses aboard the Titanic \t\n",
    "- Parch - # of parents / children aboard the Titanic \n",
    "\n",
    "##### Continuous\n",
    "\n",
    "- Age - Age in years \t\t\n",
    "- Fare - Passenger fare \n",
    "\n",
    "#### Mixed/Error-prone/Unused\n",
    "\n",
    "- PassengerId - Id of person\n",
    "- Name - Name of Passenger\n",
    "- Ticket - Ticket number \n",
    "- Cabin - Cabin number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Set warnings to not be displayed\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Divider:\n",
    "    '''\n",
    "    Table divider class\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_table, important_column):\n",
    "        '''\n",
    "        Constructor for divider\n",
    "\n",
    "        input_table - table to apply division on\n",
    "        important_column - y_column used for predictions\n",
    "        '''\n",
    "        self.result = []\n",
    "        self.input_table = input_table.copy()\n",
    "        self.important_column = important_column\n",
    "        self.connections = []\n",
    "        self.index = 0\n",
    "    \n",
    "    def get_result(self):\n",
    "        '''\n",
    "        Returns the result of calculations\n",
    "        '''\n",
    "        return self.result\n",
    "\n",
    "    def random_shrink(self, input_table, level, onehot=False, overlap=False):\n",
    "        '''\n",
    "        Recursively cluster randomly the columns\n",
    "        level - level of recursion\n",
    "        '''\n",
    "\n",
    "        input_table = input_table.copy()\n",
    "        \n",
    "        # Return if no columns\n",
    "        if len(input_table.columns) <= 1:\n",
    "            return\n",
    "        \n",
    "        # Set up base table variables\n",
    "        base_index = self.index\n",
    "        self.index += 1\n",
    "        base_index_cols = input_table.index.names\n",
    "        \n",
    "        # Apply clustering for every cluster of columns\n",
    "        while len(input_table.columns) > 0:\n",
    "\n",
    "            # Randomly shuffle\n",
    "            self.index += 1\n",
    "            mylist = np.array(range(0, len(input_table)))\n",
    "            random.shuffle(mylist)\n",
    "\n",
    "            # Randomly pick n_splits columns\n",
    "            picked_columns = []\n",
    "            if len(input_table.columns) > 1:\n",
    "                picked_columns = input_table.sample(n=np.random.randint(1, len(input_table.columns)), axis='columns').columns\n",
    "            else:\n",
    "                picked_columns = input_table.columns       \n",
    "            \n",
    "            # Set new column names\n",
    "            PK_name = 'PK' + str(level + 1) + str(self.index)\n",
    "            FK_name = 'FK' + str(level + 1) + str(self.index)\n",
    "            \n",
    "            # Add new PK\n",
    "            recursed_table = input_table[picked_columns]\n",
    "            recursed_table.loc[:, PK_name] = mylist\n",
    "            recursed_table.set_index(PK_name, inplace = True)\n",
    "\n",
    "            # Check if table size can be reduced\n",
    "            unique_recursed_table = recursed_table.drop_duplicates()\n",
    "            if len(input_table.columns) + len(input_table.index.names) > 2 and len(unique_recursed_table) < len(recursed_table):\n",
    "\n",
    "                # Add new FK and remove columns associated with it\n",
    "                old_index = list(input_table.index.names)\n",
    "                input_table = (input_table.reset_index().merge(unique_recursed_table.reset_index(), on=list(picked_columns.values), how='left')\n",
    "                .rename(columns={PK_name:FK_name})\n",
    "                .groupby(old_index + [FK_name]).mean()\n",
    "                .drop(picked_columns, axis = 1))\n",
    "                \n",
    "                # Set recursed table to have reduced element count\n",
    "                recursed_table = unique_recursed_table\n",
    "            \n",
    "            \n",
    "            # Add the connection to a list\n",
    "            self.connections.append(('table' + str(level) + str(base_index), FK_name,  \n",
    "                                     'table' + str(level + 1) + str(self.index), PK_name))\n",
    "            \n",
    "            # Append new FK table to result list\n",
    "            if len(recursed_table.columns) == 1:\n",
    "                # Check if you need to apply oneHotEncoding\n",
    "                if onehot is True and len(recursed_table[recursed_table.columns[0]].unique()) < 7:\n",
    "                    oneHotEncoder = OneHotEncoder()\n",
    "                    encoded_col = pd.DataFrame(oneHotEncoder.fit_transform(recursed_table[[recursed_table.columns[0]]]).toarray())\n",
    "\n",
    "                    # Concatenate the 2 tables\n",
    "                    recursed_table = pd.concat([recursed_table.reset_index(), encoded_col], axis=1, copy=False, join='inner')\n",
    "\n",
    "                    # Readd the index column\n",
    "                    recursed_table.loc[:, PK_name] = mylist\n",
    "                    recursed_table.set_index(PK_name, inplace = True)\n",
    "                \n",
    "                # Append single-column table to result\n",
    "                self.result.append((level + 1, self.index, recursed_table))\n",
    "                continue\n",
    "            elif overlap is True:\n",
    "                #Perform overlaping with probability\n",
    "                p = 0.3\n",
    "                if np.random.rand() <= p:\n",
    "                    picked_column = recursed_table.sample(n=1, axis='columns').columns\n",
    "                    input_table[picked_column] = recursed_table[picked_column].copy()\n",
    "            \n",
    "            # Apply clustering recursively on smaller table\n",
    "            self.random_shrink(recursed_table, level + 1, onehot=onehot, overlap=overlap)\n",
    "        \n",
    "        # Reset the index and set FK columns as normal columns\n",
    "        input_table = input_table.reset_index()\n",
    "        input_table.set_index(base_index_cols, inplace = True)\n",
    "        self.result.append((level, base_index, input_table))\n",
    "    \n",
    "\n",
    "    def random_same_pk_fk(self, input_table, level, onehot=False, overlap=False):\n",
    "        '''\n",
    "        Recursively cluster randomly the columns\n",
    "        level - level of recursion\n",
    "        '''\n",
    "\n",
    "        input_table = input_table.copy()\n",
    "        \n",
    "        # Return if no columns\n",
    "        if len(input_table.columns) <= 1:\n",
    "            return\n",
    "        \n",
    "        # Set up base table variables\n",
    "        base_index = self.index\n",
    "        self.index += 1\n",
    "        base_index_cols = input_table.index.names\n",
    "        \n",
    "        # Apply clustering for every cluster of columns\n",
    "        while len(input_table.columns) > 0:\n",
    "\n",
    "            # Randomly shuffle\n",
    "            self.index += 1\n",
    "            mylist = np.array(range(0, len(input_table)))\n",
    "            random.shuffle(mylist)\n",
    "\n",
    "            # Randomly pick n_splits columns\n",
    "            picked_columns = []\n",
    "            if len(input_table.columns) > 1:\n",
    "                picked_columns = input_table.sample(n=np.random.randint(1, len(input_table.columns)), axis='columns').columns\n",
    "            else:\n",
    "                picked_columns = input_table.columns       \n",
    "            \n",
    "            # Set new column names\n",
    "            PK_name = 'PK' + str(level + 1) + str(self.index)\n",
    "            FK_name = 'FK' + str(level + 1) + str(self.index)\n",
    "            \n",
    "            # Add new PK\n",
    "            recursed_table = input_table[picked_columns]\n",
    "            recursed_table.loc[:, PK_name] = mylist\n",
    "            recursed_table.set_index(PK_name, inplace = True)\n",
    "            \n",
    "            # Add new FK and remove columns associated with it\n",
    "            input_table.loc[:, FK_name] = mylist\n",
    "            input_table = input_table.groupby(input_table.index.names + [FK_name]).mean()\n",
    "            input_table = input_table.drop(picked_columns, axis = 1)\n",
    "            \n",
    "            # Add the connection to a list\n",
    "            self.connections.append(('table' + str(level) + str(base_index), FK_name,  \n",
    "                                     'table' + str(level + 1) + str(self.index), PK_name))\n",
    "            \n",
    "            # Append new FK table to result list\n",
    "            if len(recursed_table.columns) == 1:\n",
    "                # Check if you need to apply oneHotEncoding\n",
    "                if onehot is True and len(recursed_table[recursed_table.columns[0]].unique()) < 7:\n",
    "                    oneHotEncoder = OneHotEncoder()\n",
    "                    encoded_col = pd.DataFrame(oneHotEncoder.fit_transform(recursed_table[[recursed_table.columns[0]]]).toarray())\n",
    "\n",
    "                    # Concatenate the 2 tables\n",
    "                    recursed_table = pd.concat([recursed_table.reset_index(), encoded_col], axis=1, copy=False, join='inner')\n",
    "\n",
    "                    # Readd the index column\n",
    "                    recursed_table.loc[:, PK_name] = mylist\n",
    "                    recursed_table.set_index(PK_name, inplace = True)\n",
    "                \n",
    "                # Append single-column table to result\n",
    "                self.result.append((level + 1, self.index, recursed_table))\n",
    "                continue\n",
    "            elif overlap is True:\n",
    "                #Perform overlaping with probability\n",
    "                p = 0.3\n",
    "                if np.random.rand() <= p:\n",
    "                    picked_column = recursed_table.sample(n=1, axis='columns').columns\n",
    "                    input_table[picked_column] = recursed_table[picked_column].copy()\n",
    "            \n",
    "            # Apply clustering recursively on smaller table\n",
    "            self.random_same_pk_fk(recursed_table, level + 1, onehot=onehot, overlap=overlap)\n",
    "        \n",
    "        # Reset the index and set FK columns as normal columns\n",
    "        input_table = input_table.reset_index()\n",
    "        input_table.set_index(base_index_cols, inplace = True)\n",
    "        self.result.append((level, base_index, input_table))\n",
    "    \n",
    "    def correlation(self, input_table, important_column, level):\n",
    "        '''\n",
    "        Recursively cluster most correlated columns to an \"important_column\"\n",
    "        important_column - colum of interest, most likely to be Y\n",
    "        input_table - table to apply the clustering on\n",
    "        '''\n",
    "\n",
    "        input_table = input_table.copy()\n",
    "\n",
    "        n_splits = 3\n",
    "        \n",
    "        # Return if no columns\n",
    "        if len(input_table.columns) == 0:\n",
    "            return\n",
    "        \n",
    "        # Set up base table variables\n",
    "        base_index = self.index\n",
    "        self.index += 1\n",
    "        base_index_cols = input_table.index.names\n",
    "\n",
    "        # Calculate correlation between columns and most important column\n",
    "        corr = abs(input_table.corr(method='spearman'))\n",
    "        corr = corr.drop([important_column], axis = 1)\n",
    "        \n",
    "        # Calculate quantiles based on correlation and n_splits\n",
    "        quantiles = []\n",
    "        for i in range(n_splits):\n",
    "            quantile = 1 - (i+1) / n_splits\n",
    "            quantiles.append(corr.loc[[important_column]].T.quantile(quantile)[0])\n",
    "        \n",
    "        # Apply clustering for every cluster of columns\n",
    "        for threshold in quantiles:\n",
    "            # Randomly shuffle\n",
    "            self.index += 1\n",
    "            mylist = np.array(range(0, len(input_table)))\n",
    "            random.shuffle(mylist)\n",
    "\n",
    "            # Break if no columns\n",
    "            if len(corr.columns) == 0 or len(input_table.columns) == 0:\n",
    "                break\n",
    "        \n",
    "            # Pick the new important column\n",
    "            new_important = corr.loc[[important_column]].idxmax(axis=1)[0]\n",
    "            # Pick all columns with correlation above quantile threshold\n",
    "            corr_columns = [col for col in corr.loc[[important_column]].columns if corr.loc[[important_column]][col][0] >= threshold]\n",
    "           \n",
    "            if len(corr_columns) == 0:\n",
    "                continue\n",
    "\n",
    "             # Set new column names\n",
    "            PK_name = 'PK' + str(level + 1) + str(self.index)\n",
    "            FK_name = 'FK' + str(level + 1) + str(self.index)\n",
    "            \n",
    "            # Add new PK\n",
    "            recursed_table = input_table[corr_columns]\n",
    "            recursed_table.loc[:, PK_name] = mylist\n",
    "            recursed_table.set_index(PK_name, inplace = True)\n",
    "            \n",
    "            # Add new FK and remove columns associated with it\n",
    "            input_table.loc[:, FK_name] = mylist\n",
    "            input_table = input_table.groupby(input_table.index.names + [FK_name]).mean()\n",
    "            input_table = input_table.drop(corr_columns, axis = 1)\n",
    "            corr = corr.drop(corr_columns, axis = 1)\n",
    "            \n",
    "            # Add the connection to a list\n",
    "            self.connections.append(('table' + str(level) + str(base_index), FK_name,  \n",
    "                                     'table' + str(level + 1) + str(self.index), PK_name))\n",
    "            \n",
    "            # Apply clustering recursively\n",
    "            self.correlation(recursed_table, new_important, level + 1)\n",
    "\n",
    "        # Reset the index and set FK columns as normal columns\n",
    "        input_table = input_table.reset_index()\n",
    "        input_table.set_index(base_index_cols, inplace = True)\n",
    "        self.result.append((level, base_index, input_table))\n",
    "\n",
    "    \n",
    "    def divide(self, strategy, path, onehot=False, overlap=False):\n",
    "        '''\n",
    "        Function used to divide the table\n",
    "        strategy - strategy of division\n",
    "        path - path to save output\n",
    "        '''\n",
    "\n",
    "        # Create output folder\n",
    "        os.makedirs(path, exist_ok=True) \n",
    "        \n",
    "        # Initialise fresh result and connections lists\n",
    "        self.__init__(self.input_table, self.important_column)\n",
    "        \n",
    "        # Pick strategy\n",
    "        if strategy == 'random':\n",
    "            input_table = self.input_table.groupby(self.input_table.index.names + [self.important_column]).mean()\n",
    "            self.random_same_pk_fk(input_table, 0, onehot=onehot, overlap=overlap)\n",
    "        elif strategy == 'correlation':\n",
    "            self.correlation(self.input_table, self.important_column, 0)\n",
    "        elif strategy == 'shrink':\n",
    "            input_table = self.input_table.groupby(self.input_table.index.names + [self.important_column]).mean()\n",
    "            self.random_shrink(input_table, 0, onehot=onehot, overlap=overlap)\n",
    "        \n",
    "        # Sort result by recursion level and index\n",
    "        self.result.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "        # Print results and save every table to a file\n",
    "        print('Level, Index, Primary Key, Columns')\n",
    "        for (el, col, table) in self.result:\n",
    "            print(el, \" \", col, \" \", table.index.names, \" \", table.columns, \"\\n\")\n",
    "            table.to_csv(path + '/table' + str(el) + str(col) + '.csv')\n",
    "\n",
    "        # Initialise set of tuples in the form (table name, PK column)\n",
    "        all_tables = []\n",
    "\n",
    "        # Iterate over tables and fill data\n",
    "        for (el, col, table) in self.result:\n",
    "            # Add tables to set\n",
    "            all_tables.append((str('table' + str(el) + str(col)), table.index.names))\n",
    "\n",
    "        # Save connections to file\n",
    "        np.savetxt(path + \"/connections.csv\", self.connections, delimiter=',', fmt='%s')\n",
    "        \n",
    "        # Save tables names with their PK to file\n",
    "        all_tables = json.dumps(all_tables)\n",
    "        with open(path + '/tables.json', 'w') as outfile:\n",
    "            json.dump(all_tables, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise divider\n",
    "dv = Divider(train_data, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level, Index, Primary Key, Columns\n",
      "0   0   ['PassengerId', 'Survived']   Index(['FK12', 'FK113'], dtype='object') \n",
      "\n",
      "1   2   ['PK12']   Index(['FK24', 'FK25', 'FK29', 'FK210', 'FK211', 'FK212'], dtype='object') \n",
      "\n",
      "1   13   ['PK113']   Index(['Age'], dtype='object') \n",
      "\n",
      "2   4   ['PK24']   Index(['Fare'], dtype='object') \n",
      "\n",
      "2   5   ['PK25']   Index(['FK37', 'FK38'], dtype='object') \n",
      "\n",
      "2   9   ['PK29']   Index(['Sex'], dtype='object') \n",
      "\n",
      "2   10   ['PK210']   Index(['Parch'], dtype='object') \n",
      "\n",
      "2   11   ['PK211']   Index(['Pclass'], dtype='object') \n",
      "\n",
      "2   12   ['PK212']   Index(['Embarked'], dtype='object') \n",
      "\n",
      "3   7   ['PK37']   Index(['SibSp'], dtype='object') \n",
      "\n",
      "3   8   ['PK38']   Index(['Title'], dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply division\n",
    "# dv.divide(strategy = \"correlation\", path = 'output')\n",
    "# dv.divide(strategy = \"random\", path = 'output')\n",
    "# dv.divide(strategy = \"random\", path = 'output', onehot=True)\n",
    "# dv.divide(strategy='random', path='output', overlap=True)\n",
    "dv.divide(strategy='shrink', path = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['table00', ['PassengerId', 'Survived']], ['table12', ['PK12']], ['table113', ['PK113']], ['table24', ['PK24']], ['table25', ['PK25']], ['table29', ['PK29']], ['table210', ['PK210']], ['table211', ['PK211']], ['table212', ['PK212']], ['table37', ['PK37']], ['table38', ['PK38']]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "# Read data from tables - returns array of [table name, Primary key]\n",
    "read_tables = []\n",
    "with open('output/tables.json') as json_file:\n",
    "    read_tables = json.loads(json.load(json_file))\n",
    "print(read_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table00':                       FK12  FK113\n",
      "PassengerId Survived             \n",
      "1           0          338    566\n",
      "2           1          247    402\n",
      "3           1          453    446\n",
      "4           1          140    843\n",
      "5           0          522    843\n",
      "...                    ...    ...\n",
      "887         0          815    703\n",
      "888         1          261    238\n",
      "889         0          887    424\n",
      "890         1          107    446\n",
      "891         0          866    303\n",
      "\n",
      "[891 rows x 2 columns], 'table12':       FK24  FK25  FK29  FK210  FK211  FK212\n",
      "PK12                                       \n",
      "0      380   337   459    235    175    468\n",
      "4      164   302   459    444    227    468\n",
      "5      394   478   424    444    175    462\n",
      "9      401   309   459    444    245    462\n",
      "11      33   254   424    433    245    468\n",
      "...    ...   ...   ...    ...    ...    ...\n",
      "886     14   478   424    444    245    462\n",
      "887     45   337   459    235    245    468\n",
      "888    115    47   424    433    245    468\n",
      "889    452   302   459    444    227    468\n",
      "890     28   309   459    433    245    468\n",
      "\n",
      "[496 rows x 6 columns], 'table113':          Age\n",
      "PK113       \n",
      "566    22.00\n",
      "402    38.00\n",
      "446    26.00\n",
      "843    35.00\n",
      "551    28.00\n",
      "...      ...\n",
      "789     0.67\n",
      "619    30.50\n",
      "841     0.42\n",
      "491    34.50\n",
      "872    74.00\n",
      "\n",
      "[88 rows x 1 columns], 'table24':          Fare\n",
      "PK24         \n",
      "41     7.2500\n",
      "135   71.2833\n",
      "216    7.9250\n",
      "170   53.1000\n",
      "398    8.0500\n",
      "...       ...\n",
      "64    13.8583\n",
      "0     50.4958\n",
      "103    5.0000\n",
      "212    9.8458\n",
      "373   10.5167\n",
      "\n",
      "[248 rows x 1 columns], 'table25':       FK37  FK38\n",
      "PK25            \n",
      "0       22    17\n",
      "12      24    22\n",
      "37      22    13\n",
      "47      17    22\n",
      "48       3    17\n",
      "50      24     3\n",
      "56      26    22\n",
      "87      19    17\n",
      "120     24    13\n",
      "130     19    13\n",
      "205     22    22\n",
      "211     19     3\n",
      "223     24    20\n",
      "240     19    22\n",
      "241      3    13\n",
      "247      3    22\n",
      "254     26    13\n",
      "302     11     3\n",
      "309     26     3\n",
      "320     17    13\n",
      "332     24    17\n",
      "337     26    17\n",
      "352     17    17\n",
      "383     11    20\n",
      "395     11    17\n",
      "449     26    20\n",
      "459     11    22\n",
      "478     11    13, 'table29':       Sex\n",
      "PK29     \n",
      "459   0.0\n",
      "424   1.0, 'table210':        Parch\n",
      "PK210       \n",
      "235        2\n",
      "444        0\n",
      "433        1\n",
      "348        4\n",
      "386        3\n",
      "89         6\n",
      "469        5, 'table211':        Pclass\n",
      "PK211        \n",
      "175       0.0\n",
      "227       1.0\n",
      "245       2.0, 'table212':        Embarked\n",
      "PK212          \n",
      "468         2.0\n",
      "462         0.0\n",
      "416         1.0, 'table37':       SibSp\n",
      "PK37       \n",
      "26        1\n",
      "11        0\n",
      "24        2\n",
      "3         8\n",
      "22        5\n",
      "19        3\n",
      "17        4, 'table38':       Title\n",
      "PK38       \n",
      "17      1.0\n",
      "22      0.0\n",
      "13      2.0\n",
      "3       3.0\n",
      "20      4.0}\n"
     ]
    }
   ],
   "source": [
    "# Read data from tables - read tables as pandas and set index as Primary key column\n",
    "read_tables_content = dict()\n",
    "for [table, pk] in read_tables:\n",
    "    read_tables_content[table] = pd.read_csv('output/' + table + '.csv', index_col=pk)\n",
    "    \n",
    "print(read_tables_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>FK12</th>\n",
       "      <th>FK113</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>338</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>453</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>815</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>866</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  FK12  FK113\n",
       "PassengerId                       \n",
       "1                   0   338    566\n",
       "2                   1   247    402\n",
       "3                   1   453    446\n",
       "4                   1   140    843\n",
       "5                   0   522    843\n",
       "...               ...   ...    ...\n",
       "887                 0   815    703\n",
       "888                 1   261    238\n",
       "889                 0   887    424\n",
       "890                 1   107    446\n",
       "891                 0   866    303\n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test table reading\n",
    "table01 = pd.read_csv('output/table00.csv', index_col='PassengerId')\n",
    "table01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('table00', 'FK12'), ('table12', 'PK12')), (('table12', 'FK24'), ('table24', 'PK24')), (('table12', 'FK25'), ('table25', 'PK25')), (('table25', 'FK37'), ('table37', 'PK37')), (('table25', 'FK38'), ('table38', 'PK38')), (('table12', 'FK29'), ('table29', 'PK29')), (('table12', 'FK210'), ('table210', 'PK210')), (('table12', 'FK211'), ('table211', 'PK211')), (('table12', 'FK212'), ('table212', 'PK212')), (('table00', 'FK113'), ('table113', 'PK113'))]\n"
     ]
    }
   ],
   "source": [
    "# Read all ((table1, PK), (table2, FK)) relations and add them to a list\n",
    "read_connections = map(lambda x: ((x[0], x[1]), (x[2], x[3])), genfromtxt('output/connections.csv', delimiter=',', dtype='str'))\n",
    "read_connections = list(read_connections)\n",
    "print(read_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FK12  FK113  FK24  FK25  FK29  FK210  FK211  FK212\n",
      "0     338    566    41   254   424    444    245    468\n",
      "1     247    402   135   309   459    444    175    462\n",
      "2     453    446   216   395   459    444    245    468\n",
      "3     453    703   216   395   459    444    245    468\n",
      "4     453    424   216   395   459    444    245    468\n",
      "..    ...    ...   ...   ...   ...    ...    ...    ...\n",
      "886   870    566   373   395   459    444    245    468\n",
      "887   836    436   358   302   459    469    245    416\n",
      "888   261    238   176   395   459    444    175    468\n",
      "889   887    424    45   337   459    235    245    468\n",
      "890   107    446   176   478   424    444    175    462\n",
      "\n",
      "[891 rows x 8 columns]\n",
      "     FK24  FK25  FK29  FK210  FK211  FK212      Fare\n",
      "0     380   337   459    235    175    468  151.5500\n",
      "1     380   395   459    444    175    468  151.5500\n",
      "2     380   309   459    235    175    468  151.5500\n",
      "3     380    56   424    235    175    468  151.5500\n",
      "4     164   302   459    444    227    468   12.6500\n",
      "..    ...   ...   ...    ...    ...    ...       ...\n",
      "491   373   395   459    444    245    468   10.5167\n",
      "492   466   478   424    433    175    462   61.9792\n",
      "493    65   478   424    433    175    462   63.3583\n",
      "494   438   395   459    444    245    416    8.0292\n",
      "495   408   254   424    444    245    468   15.5500\n",
      "\n",
      "[496 rows x 7 columns]\n",
      "     FK24  FK25  FK29  FK210  FK211  FK212  FK37  FK38\n",
      "0     380   337   459    235    175    468    26    17\n",
      "1     251   337   459    433    227    468    26    17\n",
      "2       2   337   459    444    245    416    26    17\n",
      "3     434   337   459    235    175    468    26    17\n",
      "4     329   337   459    444    245    468    26    17\n",
      "..    ...   ...   ...    ...    ...    ...   ...   ...\n",
      "491   352    12   424    433    227    468    24    22\n",
      "492    37   352   459    235    245    468    17    17\n",
      "493   216   352   459    235    245    468    17    17\n",
      "494   118   352   459    235    245    468    17    17\n",
      "495   279     0   459    235    245    468    22    17\n",
      "\n",
      "[496 rows x 8 columns]\n",
      "    FK37  FK38  SibSp\n",
      "0     22    17      5\n",
      "1     22    13      5\n",
      "2     22    22      5\n",
      "3     24    22      2\n",
      "4     24     3      2\n",
      "5     24    13      2\n",
      "6     24    20      2\n",
      "7     24    17      2\n",
      "8     17    22      4\n",
      "9     17    13      4\n",
      "10    17    17      4\n",
      "11     3    17      8\n",
      "12     3    13      8\n",
      "13     3    22      8\n",
      "14    26    22      1\n",
      "15    26    13      1\n",
      "16    26     3      1\n",
      "17    26    17      1\n",
      "18    26    20      1\n",
      "19    19    17      3\n",
      "20    19    13      3\n",
      "21    19     3      3\n",
      "22    19    22      3\n",
      "23    11     3      0\n",
      "24    11    20      0\n",
      "25    11    17      0\n",
      "26    11    22      0\n",
      "27    11    13      0\n",
      "    FK37  FK38  Title\n",
      "0     22    17    1.0\n",
      "1      3    17    1.0\n",
      "2     19    17    1.0\n",
      "3     24    17    1.0\n",
      "4     26    17    1.0\n",
      "5     17    17    1.0\n",
      "6     11    17    1.0\n",
      "7     24    22    0.0\n",
      "8     17    22    0.0\n",
      "9     26    22    0.0\n",
      "10    22    22    0.0\n",
      "11    19    22    0.0\n",
      "12     3    22    0.0\n",
      "13    11    22    0.0\n",
      "14    22    13    2.0\n",
      "15    24    13    2.0\n",
      "16    19    13    2.0\n",
      "17     3    13    2.0\n",
      "18    26    13    2.0\n",
      "19    17    13    2.0\n",
      "20    11    13    2.0\n",
      "21    24     3    3.0\n",
      "22    19     3    3.0\n",
      "23    11     3    3.0\n",
      "24    26     3    3.0\n",
      "25    24    20    4.0\n",
      "26    11    20    4.0\n",
      "27    26    20    4.0\n",
      "     FK24  FK25  FK29  FK210  FK211  FK212  Sex\n",
      "0     380   337   459    235    175    468  0.0\n",
      "1     164   302   459    444    227    468  0.0\n",
      "2     401   309   459    444    245    462  0.0\n",
      "3      38   395   459    235    175    468  0.0\n",
      "4      30   302   459    348    245    468  0.0\n",
      "..    ...   ...   ...    ...    ...    ...  ...\n",
      "491   112   478   424    444    245    462  1.0\n",
      "492     2   254   424    433    245    468  1.0\n",
      "493   408   254   424    444    245    468  1.0\n",
      "494    14   478   424    444    245    462  1.0\n",
      "495   115    47   424    433    245    468  1.0\n",
      "\n",
      "[496 rows x 7 columns]\n",
      "     FK24  FK25  FK29  FK210  FK211  FK212  Parch\n",
      "0     380   337   459    235    175    468      2\n",
      "1      38   395   459    235    175    468      2\n",
      "2      39   459   424    235    245    468      2\n",
      "3     391   247   424    235    245    468      2\n",
      "4     434   337   459    235    175    468      2\n",
      "..    ...   ...   ...    ...    ...    ...    ...\n",
      "491   115   302   459    469    245    468      5\n",
      "492   118   254   424    469    245    468      5\n",
      "493   118   309   459    469    245    468      5\n",
      "494    37   309   459    469    245    468      5\n",
      "495   358   302   459    469    245    416      5\n",
      "\n",
      "[496 rows x 7 columns]\n",
      "     FK24  FK25  FK29  FK210  FK211  FK212  Pclass\n",
      "0     380   337   459    235    175    468     0.0\n",
      "1     394   478   424    444    175    462     0.0\n",
      "2      38   395   459    235    175    468     0.0\n",
      "3     440   478   424    444    175    462     0.0\n",
      "4     143   395   459    444    175    462     0.0\n",
      "..    ...   ...   ...    ...    ...    ...     ...\n",
      "491   408   254   424    444    245    468     2.0\n",
      "492    14   478   424    444    245    462     2.0\n",
      "493    45   337   459    235    245    468     2.0\n",
      "494   115    47   424    433    245    468     2.0\n",
      "495    28   309   459    433    245    468     2.0\n",
      "\n",
      "[496 rows x 7 columns]\n",
      "     FK24  FK25  FK29  FK210  FK211  FK212  Embarked\n",
      "0     380   337   459    235    175    468       2.0\n",
      "1     164   302   459    444    227    468       2.0\n",
      "2      33   254   424    433    245    468       2.0\n",
      "3      38   395   459    235    175    468       2.0\n",
      "4      30   302   459    348    245    468       2.0\n",
      "..    ...   ...   ...    ...    ...    ...       ...\n",
      "491   358   302   459    469    245    416       1.0\n",
      "492   128   395   459    444    245    416       1.0\n",
      "493     2   254   424    444    245    416       1.0\n",
      "494    92   478   424    444    245    416       1.0\n",
      "495   438   395   459    444    245    416       1.0\n",
      "\n",
      "[496 rows x 7 columns]\n",
      "     FK12  FK113    Age\n",
      "0     338    566  22.00\n",
      "1     195    566  22.00\n",
      "2     873    566  22.00\n",
      "3     774    566  22.00\n",
      "4     522    566  22.00\n",
      "..    ...    ...    ...\n",
      "886    58    619  30.50\n",
      "887   522    619  30.50\n",
      "888   171    841   0.42\n",
      "889   688    491  34.50\n",
      "890   378    872  74.00\n",
      "\n",
      "[891 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example of joining tables by going over the relations list\n",
    "for ((table1, index1), (table2, index2)) in read_connections:\n",
    "    print(read_tables_content[table1].merge(read_tables_content[table2], left_on=index1, right_on=index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Example of joining tables by going over the relations list\n",
    "((table1, index1), (table2, index2)) = read_connections[0]\n",
    "joined_table = read_tables_content[table1]\n",
    "old_index = list(joined_table.index.names)\n",
    "\n",
    "joined_table = (joined_table.reset_index().merge(read_tables_content[table2], left_on=index1, right_on=index2)\n",
    "    .groupby(old_index).mean()\n",
    "    .drop([index1], axis=1))\n",
    "\n",
    "for i in range(len(read_connections) - 1):\n",
    "    ((table1, index1), (table2, index2)) = read_connections[i+1]\n",
    "\n",
    "    old_index = list(joined_table.index.names)\n",
    "\n",
    "    joined_table = (joined_table.reset_index().merge(read_tables_content[table2], left_on=index1, right_on=index2)\n",
    "    .groupby(old_index).mean()\n",
    "    .drop([index1], axis=1))\n",
    "\n",
    "print(joined_table.reset_index().sort_index().sort_index(axis=1).equals(train_data.reset_index().sort_index().sort_index(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
